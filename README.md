# AI-Driven Hiring Platform (ATS)

A modern, intelligent Applicant Tracking System built with FastAPI backend, Next.js frontend, and machine learning models for automated resume parsing and candidate matching.

## ğŸš€ Features

### Core Functionality
- **Smart Resume Parsing**: AI-powered extraction of candidate information from various resume formats
- **Intelligent Job Matching**: ML-based algorithms to match candidates with job requirements
- **HR Dashboard**: Comprehensive interface for managing candidates, jobs, and hiring pipeline
- **Secure Authentication**: JWT-based authentication system with role-based access control
- **Real-time Analytics**: Hiring metrics, candidate statistics, and performance insights

### Advanced Features (Planned)
- **Interview Intelligence**: Real-time AI analysis during interviews
  - Sentiment analysis (confident, nervous, engaged)
  - Dynamic question recommendations based on job requirements
  - Conversation flow insights and candidate assessment
- **Automated Screening**: Pre-screening candidates based on customizable criteria
- **Integration APIs**: Connect with popular HR tools and platforms

## ğŸ—ï¸ Architecture

### Technology Stack

**Backend**
- **FastAPI**: Modern, fast web framework with automatic API documentation
- **PostgreSQL**: Robust relational database for data persistence
- **SQLAlchemy**: Python ORM for database operations
- **Alembic**: Database migration management
- **Python 3.10+**: Core programming language

**Frontend**
- **Next.js 14**: React framework with App Router and server-side rendering
- **TypeScript**: Type-safe JavaScript for better development experience
- **Tailwind CSS**: Utility-first CSS framework for rapid UI development
- **React Hook Form**: Performant forms with easy validation

**Machine Learning**
- **Python ML Stack**: scikit-learn, pandas, numpy for data processing
- **NLP Libraries**: spaCy, NLTK, or Transformers for text processing
- **Jupyter Notebooks**: Model experimentation and development

**DevOps**
- **Docker**: Containerization for consistent environments
- **Docker Compose**: Multi-container application orchestration

## ğŸ“ Project Structure

```
ATS/
â”œâ”€â”€ backend/                    # FastAPI Backend
â”‚   â”œâ”€â”€ app/                   # Main application code
â”‚   â”‚   â”œâ”€â”€ api/              # API routes and endpoints
â”‚   â”‚   â”œâ”€â”€ core/             # Configuration and security
â”‚   â”‚   â”œâ”€â”€ models/           # SQLAlchemy ORM models
â”‚   â”‚   â”œâ”€â”€ services/         # Business logic layer
â”‚   â”‚   â””â”€â”€ main.py           # FastAPI application entry point
â”‚   â”œâ”€â”€ tests/                # Test suite (Pytest)
â”‚   â”œâ”€â”€ alembic.ini           # Database migration configuration
â”‚   â”œâ”€â”€ requirements.txt      # Python dependencies
â”‚   â”œâ”€â”€ Dockerfile           # Container configuration
â”‚   â””â”€â”€ .env                 # Environment variables
â”‚
â”œâ”€â”€ frontend/                  # Next.js Frontend
â”‚   â”œâ”€â”€ app/                  # Next.js App Router pages
â”‚   â”œâ”€â”€ components/           # Reusable React components
â”‚   â”œâ”€â”€ hooks/               # Custom React hooks
â”‚   â”œâ”€â”€ lib/                 # Utility functions and configurations
â”‚   â”œâ”€â”€ schema/              # TypeScript schemas and validation
â”‚   â”œâ”€â”€ server/              # Server-side utilities
â”‚   â”œâ”€â”€ types/               # TypeScript type definitions
â”‚   â”œâ”€â”€ package.json         # Node.js dependencies
â”‚   â”œâ”€â”€ next.config.mjs      # Next.js configuration
â”‚   â”œâ”€â”€ tailwind.config.ts   # Tailwind CSS configuration
â”‚   â”œâ”€â”€ tsconfig.json        # TypeScript configuration
â”‚   â”œâ”€â”€ Dockerfile           # Container configuration
â”‚   â”œâ”€â”€ .env.development     # Development environment variables
â”‚   â””â”€â”€ .env.production      # Production environment variables
â”‚
â”œâ”€â”€ ml_models/                 # Machine Learning Models
â”‚   â”œâ”€â”€ nlp_model.py          # NLP model for resume parsing
â”‚   â”œâ”€â”€ experimental.ipynb    # Jupyter notebook for experiments
â”‚   â”œâ”€â”€ Dockerfile           # Container configuration
â”‚   â””â”€â”€ models/              # Trained model files (not in git)
â”‚
â”œâ”€â”€ docker-compose.yml         # Multi-container orchestration
â”œâ”€â”€ ATS.code-workspace        # VS Code workspace configuration
â”œâ”€â”€ .gitignore               # Git ignore rules
â””â”€â”€ README.md                # This file
```

## ğŸš¦ Quick Start

### Prerequisites

- **Docker & Docker Compose**: For containerized development
- **Node.js 18+**: For local frontend development
- **Python 3.10+**: For local backend development
- **PostgreSQL**: Database (handled by Docker in development)

### ğŸ³ Running with Docker (Recommended)

1. **Clone the repository**
```bash
git clone https://github.com/ahmedtarekabd/elevatrio-ats.git
cd elevatrio-ats
```

2. **Start all services**
```bash
docker-compose up --build
```

3. **Access the applications**
   - **Frontend**: http://localhost:8501
   - **Backend API**: http://localhost:8000
   - **API Documentation**: http://localhost:8000/docs
   - **API Redoc**: http://localhost:8000/redoc

### ğŸ”§ Local Development Setup

#### Backend Development

```bash
cd backend

# Create virtual environment
python -m venv venv
source venv/bin/activate  # Windows: .\venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Set up environment variables
cp .env.example .env  # Edit with your settings

# Run database migrations
alembic upgrade head

# Start development server
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

#### Frontend Development

```bash
cd frontend

# Install dependencies
npm install

# Set up environment variables
cp .env.development.example .env.development  # Edit with your settings

# Start development server
npm run dev
```

## ğŸ” Environment Configuration

### Backend (.env)
```env
# Database
DATABASE_URL=postgresql://user:password@localhost:5432/ats_db

# Security
SECRET_KEY=your-super-secret-key-here
ALGORITHM=HS256
ACCESS_TOKEN_EXPIRE_MINUTES=30

# External APIs
OPENAI_API_KEY=your-openai-key  # For AI features
```

### Frontend (.env.development)
```env
# API Configuration
NEXT_PUBLIC_API_URL=http://localhost:8000
NEXT_PUBLIC_APP_ENV=development

# Authentication
NEXTAUTH_SECRET=your-nextauth-secret
NEXTAUTH_URL=http://localhost:8501
```

## ğŸ“Š Database Management

### Running Migrations

```bash
cd backend

# Create a new migration
alembic revision --autogenerate -m "Description of changes"

# Apply migrations
alembic upgrade head

# Rollback migration
alembic downgrade -1
```

### Database Seeding

```bash
cd backend
python -m app.db.db_seed
```

## ğŸ§ª Testing

### Backend Tests

```bash
cd backend
pytest tests/ -v
```

### Frontend Tests

```bash
cd frontend
npm test
```

## ğŸ“– API Documentation

Once the backend is running, visit:
- **Swagger UI**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc

### Key API Endpoints

- **Authentication**: `/auth/login`, `/auth/register`
- **Jobs**: `/jobs/`, `/jobs/{id}`
- **Candidates**: `/candidates/`, `/candidates/{id}`
- **Resume Upload**: `/candidates/upload-resume`
- **Job Matching**: `/matching/candidates/{job_id}`

## ğŸš€ Deployment

### Production Docker Build

```bash
# Build production images
docker-compose -f docker-compose.prod.yml build

# Deploy with production configuration
docker-compose -f docker-compose.prod.yml up -d
```

### Cloud Deployment Options

1. **AWS ECS/Fargate**: Serverless container deployment
2. **Google Cloud Run**: Fully managed container platform
3. **Azure Container Instances**: Scalable container hosting
4. **DigitalOcean App Platform**: Simple container deployment

### CI/CD Pipeline Example (GitHub Actions)

```yaml
name: CI/CD Pipeline
on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - name: Run backend tests
        run: |
          cd backend
          pip install -r requirements.txt
          pytest
      - name: Run frontend tests
        run: |
          cd frontend
          npm install
          npm test

  deploy:
    needs: test
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    steps:
      - name: Deploy to production
        run: |
          # Add deployment steps here
          echo "Deploying to production..."
```

## ğŸ¤ Contributing

1. **Fork the repository**
2. **Create a feature branch**: `git checkout -b feature/amazing-feature`
3. **Commit your changes**: `git commit -m 'Add amazing feature'`
4. **Push to the branch**: `git push origin feature/amazing-feature`
5. **Open a Pull Request**

### Development Guidelines

- Follow PEP 8 for Python code
- Use ESLint and Prettier for TypeScript/JavaScript code
- Write tests for new features
- Update documentation as needed
- Follow conventional commit messages

## ğŸ“ Code Quality

### Backend
- **Linting**: `flake8`, `black`
- **Type Checking**: `mypy`
- **Testing**: `pytest`

### Frontend
- **Linting**: ESLint
- **Formatting**: Prettier
- **Type Checking**: TypeScript compiler

## ğŸ› Troubleshooting

### Common Issues

1. **Database Connection Errors**
   - Ensure PostgreSQL is running
   - Check DATABASE_URL in .env file
   - Verify database credentials

2. **Frontend Can't Connect to Backend**
   - Verify NEXT_PUBLIC_API_URL in frontend environment
   - Check if backend is running on correct port
   - Ensure CORS is properly configured

3. **Docker Issues**
   - Run `docker-compose down && docker-compose up --build`
   - Check Docker daemon is running
   - Verify port availability

### Logs and Debugging

```bash
# View container logs
docker-compose logs backend
docker-compose logs frontend

# Follow logs in real-time
docker-compose logs -f backend
```

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- FastAPI for the excellent Python web framework
- Next.js team for the React framework
- OpenAI for AI/ML capabilities
- The open-source community for various libraries and tools
